<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Notheastern CS7150 Deep Learning</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Jiaji Huang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="bio.html">Bio</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="research_summary.html">Summary</a></div>
<div class="menu-item"><a href="pub.html">Publications</a></div>
<div class="menu-item"><a href="software.html">Software</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="CS7150.html" class="current">Deep&nbsp;Learning</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Notheastern CS7150 Deep Learning</h1>
</div>
<h2>Course Information</h2>
<p>Deep learning is a subfield of machine learning that builds highly parameterized (deep) models from large volume of data, widely deployed in many industrial systems.
Applications cover computer vision, language, speech, robotics, etc. Deep learning advances so rapidly that it has become one of the most popular field to study.
</p>
<p>This course will introduce students to
</p>
<p>1) basic building blocks of deep models, e.g., convolution, activation functions, attention
</p>
<p>2) typical architectures, e.g., encoder-decoder for seq-to-seq tasks
</p>
<p>3) training and evaluation of these models, e.g., variants of stochastic optimizers
</p>
<p>Some cutting edge research topics will also be discussed, e.g., interpretability, model compression, self-supervised pretraining. There will be a course project that encourages student to explore more of these open-ended problems.
</p>
<h2>Class & Links</h2>
<p>Lecture: Saturday 9:00 am - 12:20 pm
</p>
<p>Office hours: Saturday 2:00 pm - 3:00 pm 
</p>
<p>TA: Pratyaksh Bhalla (bhalla.pr@northeastern.edu)
</p>
<p>Textbooks:
</p>
<ul>
<li><p><a href="https://www.deeplearningbook.org" target=&ldquo;blank&rdquo;>Deep Learning</a> by Goodfellow, Bengio and Courville
</p>
</li>
<li><p><a href="https://www.bishopbook.com" target=&ldquo;blank&rdquo;>Deep Learning, Foundations and Concepts</a> by C. M. Bishop and H. Bishop
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2201.02135" target=&ldquo;blank&rdquo;>Deep Reinforcement Learning</a> by Plaat

</p>
</li>
</ul>
<p>Grade: 20% homework + 20% paper presentation + 20% midterm exam + 40% project
</p>
<p>Paper presentation: Each student presents one paper in one of the classes. We reward good presenters and actively involved audience.
The paper could be one of those suggested reading materials in the last class, or any recent paper identified as relevant by the presenter.
</p>
<h2>Syllabus</h2>
<p>01/13
</p>
<ul>
<li><p>Topics: Introduction, Prerequisites <a href="files/teaching/deep_learning/1.pdf" target=&ldquo;blank&rdquo;>[slides]</a>
</p>
</li>
<li><p>Readings: textbook chapters <a href="https://www.deeplearningbook.org/contents/linear_algebra.html" target=&ldquo;blank&rdquo;>linear algerbra</a>, <a href="https://www.deeplearningbook.org/contents/prob.html" target=&ldquo;blank&rdquo;>probabilities</a>, <a href="https://proceedings.mlr.press/v206/kleindessner23a/kleindessner23a.pdf" target=&ldquo;blank&rdquo;>fair PCA</a>
</p>
</li>
<li><p>Assignment: <a href="files/teaching/deep_learning/hw1.pdf" target=&ldquo;blank&rdquo;>[homework1]</a> 
</p>
</li>
</ul>
<p>01/20
</p>
<ul>
<li><p>Topics: Convolutional network and computer vision
</p>
</li>
<li><p>Readings: <a href="https://arxiv.org/pdf/1512.03385.pdf" target=&ldquo;blank&rdquo;>ResNet</a>, <a href="https://arxiv.org/pdf/1608.06993.pdf" target=&ldquo;blank&rdquo;>DenseNet</a>
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>01/27
</p>
<ul>
<li><p>Topics: RNN, LSTM, Transformer
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>02/03
</p>
<ul>
<li><p>Topics: NLP and Speech applications, Seq-to-Seq Models
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>02/10
</p>
<ul>
<li><p>Topics: Back propagation, stochastic optimizers, parallelism
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>02/17
</p>
<ul>
<li><p>Topics: Overfitting, Generalization
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>02/24
Midterm Exam
</p>
<p>03/02
</p>
<ul>
<li><p>Topics: Large Language Models, finetuning methods
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>03/09
</p>
<ul>
<li><p>Topics: Sparsity, Distillation, Model Compression
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>03/16:
</p>
<ul>
<li><p>Topics: Interpretability, Information bottleneck, adverserial attacks
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment
</p>
</li>
</ul>
<p>03/23
</p>
<ul>
<li><p>Topics: Multi-task Learning, meta-learning, zero-shot Learning
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment
</p>
</li>
</ul>
<p>03/30
</p>
<ul>
<li><p>Topics: Generative Models
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment
</p>
</li>
</ul>
<p>04/06
</p>
<ul>
<li><p>Topics: Reinforcement Learning (Guest Lecture)
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>04/13
</p>
<ul>
<li><p>Topics: Graph Neural Networks (Guest Lecture)
</p>
</li>
<li><p>Readings:
</p>
</li>
<li><p>Assignment:
</p>
</li>
</ul>
<p>04/20
</p>
<ul>
<li><p>Final Project Presentation 1
</p>
</li>
</ul>
<p>04/27
</p>
<ul>
<li><p>Final Project Presentation 2
</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
