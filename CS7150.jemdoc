# jemdoc: menu{MENU}{CS7150.html}, nofooter
= Notheastern CS7150 Deep Learning


== Course Information
Deep learning is a subfield of machine learning that builds highly parameterized (deep) models from large volume of data, widely deployed in many industrial systems.
Applications cover computer vision, language, speech, robotics, etc. Deep learning advances so rapidly that it has become one of the most popular field to study.

This course will introduce students to

1) basic building blocks of deep models, e.g., convolution, activation functions, attention

2) typical architectures, e.g., encoder-decoder for seq-to-seq tasks

3) training and evaluation of these models, e.g., variants of stochastic optimizers

Some cutting edge research topics will also be discussed, e.g., interpretability, model compression, self-supervised pretraining. There will be a course project that encourages student to explore more of these open-ended problems.


== Class \& Links
Lecture: Saturday 9:00 am - 12:20 pm

Office hours: Saturday 1:00 pm - 3:00 pm 

TA: Pratyaksh Bhalla (bhalla.pr@northeastern.edu)

TA office hours: Friday morning (check with TA though)

Textbooks:
- [https://www.deeplearningbook.org Deep Learning] by Goodfellow, Bengio and Courville
- [https://www.bishopbook.com Deep Learning, Foundations and Concepts] by C. M. Bishop and H. Bishop
- [https://arxiv.org/abs/2201.02135 Deep Reinforcement Learning] by Plaat
#- [https://inst.eecs.berkeley.edu/~cs188/sp20/assets/files/SuttonBartoIPRLBook2ndEd.pdf Reinforcement Learning: An Introduction 2nd Edition] by Sutton and Barto

Grade: 20\% homework \+ 20\% paper presentation \+ 20\% midterm exam \+ 40\% project

Homework: Due Friday 11:59pm

Paper presentation: Each student presents one paper in one of the classes. We reward good presenters and actively involved audience.
The paper could be one of those suggested reading materials in the previous classes, or any recent paper identified as relevant by the presenter.
There is no restriction/preference on form of the presentation. Slides may be used for clarity. Whiteboard can be used for derivations if necessary.

Khoury cloud: [files/teaching/Khoury_cloud.pdf instruction1], [files/teaching/Khoury_cloud2.pdf instruction2]

General Policies:
- Attend regularly: If you cannot make it, please email me or TA. Note: 2+ absence can harm your grade
- Academic integrity (check [https://osccr.sites.northeastern.edu/academic-integrity-policy here]): In your homework or final project,
	-- if you copied code somewhere from the web, please put a comment of the link
	-- if you discussed with others, please acknowledge your collaborator
	-- if you used chatgpt or any of its equivalent, please say so

== Schedules
01\/13
- Topics: Introduction, Prerequisites [files/teaching/deep_learning/1.pdf \[slides\]]
- Readings: textbook chapters [https://www.deeplearningbook.org/contents/linear_algebra.html linear algerbra], [https://www.deeplearningbook.org/contents/prob.html probabilities], [https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html PyTorch tutorial page]
- Assignment: [files/teaching/deep_learning/hw1.pdf \[homework1\]]

01\/20
- Topics: Convolutional network and computer vision
- Readings: [https://arxiv.org/pdf/1512.03385.pdf ResNet], [https://arxiv.org/pdf/1608.06993.pdf DenseNet]
- Assignment:

01\/27
- Topics: RNN, LSTM, Transformer and language modeling
- Readings: [https://arxiv.org/abs/2006.12070 Lipschitz RNN]
- Assignment:

02\/03
- Topics: NLP and Speech applications, Seq-to-Seq Models
- Readings:
- Assignment:

02\/10
- Topics: Back propagation, stochastic optimizers, parallelism
- Readings:
- Assignment:

02\/17
- Topics: Overfitting, Generalization
- Readings:
- Assignment:

02\/24
Midterm Exam

03\/02
- Topics: Large Language Models, finetuning methods
- Readings:
- Assignment:

03\/09
- Topics: Sparsity, Distillation, Model Compression
- Readings:
- Assignment:

03\/16:
- Topics: Interpretability, Information bottleneck, adverserial attacks
- Readings:
- Assignment

03\/23
- Topics: Multi-task Learning, meta-learning, zero-shot Learning
- Readings:
- Assignment

03\/30
- Topics: Generative Models
- Readings:
- Assignment

04\/06
- Topics: Reinforcement Learning (Guest Lecture by [https://kaixianglin.github.io Kaixiang Lin])
- Readings:
- Assignment:

04\/13
- Topics: Graph Neural Networks (Guest Lecture by [https://www.linkedin.com/in/jian-zhang-a080271b/ Jian Zhang])
- Readings:
- Assignment:

04\/20
- Final Project Presentation 1

04\/27
- Final Project Presentation 2
